{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    postingList = [['dog', 'my', 'has']]\n",
    "    classVec = [0, 1, 0, 1, 0, 1] # 1是好的 0是坏的\n",
    "    \n",
    "    return postingList, classVec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    def __init__(self): #--默认构造方法\n",
    "        self.vocabulary = []      #词典\n",
    "        self.idf = 0              #词典的IDF权值向量\n",
    "        self.tf = 0               #训练集的权值矩阵\n",
    "        self.tdm = 0              #P(x|yi)\n",
    "        self.Pcates = {}          #P(yi)对应一个类别\n",
    "        self.labels = []          #对应每个文本的分类，是一个外部导入的列表\n",
    "        self.doclength = 0         #训练集文本数\n",
    "        self.vocablen = 0         #词典词长\n",
    "        self.testset = 0          #测试集\n",
    "        \n",
    "    def train_set(self, trainset, classVec): #--导入训练集和测试集，生成算法必要的参数和数据结构\n",
    "        self.cate_prob(classVec)       #计算每个分类在数据集中的概率P(yi)\n",
    "        self.doclenth = len(trainset)\n",
    "        tempset = set()\n",
    "        [tempset.add(word) for doc in trainset for word in doc] #生成词典\n",
    "        self.vocabulary = list(tempset)\n",
    "        self.vocablen = len(self.vocabulary)\n",
    "        \n",
    "        self.calc_wordfreq(trainset)   #计算词频数据集\n",
    "        self.build_tdm()               #按分类累计向量空间的每维值P(x|yi)\n",
    "        \n",
    "    def cate_prob(self, classVec): #--计算在数据集中每个分类的概率P(yi)\n",
    "        self.labels = classVec\n",
    "        labeltemps = set(self.labels)  #获取全部分类\n",
    "        for labeltemp in labeltemps:\n",
    "            #统计列表中重复的分类: self.label.count(labeltemp)\n",
    "            self.Pcates[labeltemp] = float(self.labels.count(labeltemp)) / float(len(self.labels))\n",
    "    \n",
    "    def calc_wordfreq(self, trainset): #-- 生成普通的词频向量\n",
    "        self.idf = np.zeros([1, self.vocablen])  #1*词典数\n",
    "        self.tf = np.zeros([self.doclength, self.vocablen]) #训练集文件数*词典数\n",
    "        \n",
    "        for indx in xrange(self.doclength): #遍历所有的文本\n",
    "            for word in trainset[indx]:     #遍历文本中的每个词\n",
    "                #找到文本的词在字典中的位置+1\n",
    "                self.tf[indx, self.vocabulary.index(word)] += 1\n",
    "            for signleword in set(trainset[indx]):\n",
    "                self.idf[0, self.vocabulary.index(signleword)] += 1\n",
    "                \n",
    "    def build_tdm(self): #--按分类累计计算向量空间的每维值P(x|yi)\n",
    "        self.tdm = np.zeros([len(self.Pcates), self.vocablen]) #类别行*词典列\n",
    "        sumlist = np.zeros([len(self.Pcates), 1])               #统计每个分类的总值\n",
    "        for indx in xrange(self.doclength):\n",
    "            #将同一类别的词向量空间值加总\n",
    "            self.tdm[self.labels[indx]] = np.sum(self.labels[indx])\n",
    "            #统计每个分类的总值，标量\n",
    "            sumlist[self.labels[indx]] = np.sum(self.tdm[self.labels[indx]])\n",
    "        self.tdm = self.tdm / sumlist   #生成P(x|yi)\n",
    "        \n",
    "    def map2vocab(self, testdata): #--将测试集映射到当前词典\n",
    "        self.testset = np.zeros([1, self.vocablen])\n",
    "        for word in testdata:\n",
    "            self.testset[0, self.vocabulary.index(word)] += 1\n",
    "            \n",
    "    def predict(self, testset): #-- 预测分类结果，输出预测的分类类别\n",
    "        if np.shape(testset) [1] != self.vocablen: #如果测试集长度与词典不相等，则推出程序\n",
    "            print \"输入错误\"\n",
    "            exit(0)\n",
    "            \n",
    "        predvalue = 0 #初始化类别概率\n",
    "        predclass = 0 #初始化类别名称\n",
    "        for tdm_vect, keyclass in zip(self.tdm, self.Pcates):\n",
    "            #P(x|yi) P(yi)\n",
    "            #变量tdm，计算最大分类值\n",
    "            temp = np.sum(testset*tdm_vect*self.Pcates[keyclass])\n",
    "            if temp > predvalue:\n",
    "                predvalue = temp\n",
    "                predclass = keyclass\n",
    "        return predclass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "改进词频向量函数:wordfreq\n",
    "\n",
    "使用TF-IDF策略，修正多种偏差\n",
    "\n",
    "calc_tfidf()\n",
    "'''\n",
    "\n",
    "def clac_tfidf(self, trainset):\n",
    "    self.idf = np.zeros([1, self.vocablen])\n",
    "    self.tf = np.zeros([self.doclength, self.vocablen])\n",
    "    \n",
    "    for indx in xrange(self.doclength):\n",
    "        for word in trainset[indx]:\n",
    "            self.tf[indx, self.vocabulary.index(word)] += 1\n",
    "        #消除不同句长导致的偏差\n",
    "        self.tf[indx] = self.tf(indx) / float(len(trainset[indx]))\n",
    "        for signleword in set(trainset[indx]):\n",
    "            self.idf[0, self.vocabulary.index(signleword)] += 1\n",
    "    self.idf = np.log(float(self.doclength) / self.idf)\n",
    "    self.tf = np.multiply(self.tf, self.idf) #矩阵与向量的点积 ， TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:50: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "获取结果\n",
    "'''\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from numpy import*\n",
    "import numpy as np\n",
    "\n",
    "dataset, listClasses = loadDataSet() #导入数据集\n",
    "#dataset：句子的词向量\n",
    "#listclass: 句子所属的类别[0,1,0,1,0,1]\n",
    "nb = NaiveBayes()                    #实例化\n",
    "nb.train_set(dataset, listClasses)   #训练数据集\n",
    "nb.map2vocab(dataset[0])               #随机选一个测试句\n",
    "print nb.predict(nb.testset)         #输出分类类别\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
